---
title: "Sitzung 4: Topic Modeling"
author: "Valerie Hase & Luisa Kutlar"
format:
  html:
    toc: true
    html-math-method: katex
    css: styles.css
---

# 1. Pakete laden und Daten einlesen

Zun√§chst installieren alle Pakete, die wir f√ºr diese Sitzung brauchten (z.B. `tidyverse`). Ihr braucht `install.packages()` nur, wenn ihr die Pakete im Methodencafe noch nicht installiert hattet.

```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
#install.packages("tidyverse)
#install.packages("RCurl")
#install.packages("quanteda")
#install.packages("stm")
#install.packages("reshape2")

library("tidyverse")
library("RCurl")
library("quanteda")
library("stm")
library("reshape2")
```
Neu hinzugekommen seit dem Methodencafe ist das `stminsights`-Paket, das ihr neu installieren m√ºsstest.

Wenn das bei euch nicht klappt, ist das kein Problem - wir brauchen das Paket nur f√ºr eine zus√§tzliche Analyse am Ende.
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE, eval = FALSE}
install.packages("stminsights")
library("stminsights")
```
Nun lesen wir die Daten wieder ein und f√ºhren die bereits erlernten Preprocessing-Schritte, inkl. der Transformation in eine Document-Feature-Matrix, aus:
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Daten laden
url <-  getURL("https://raw.githubusercontent.com/valeriehase/textasdata-ms/main/data/data_tvseries.csv")
data <- read.csv2(text = url)

# Preprocessing
tokens <- tokens(data$Description,
                 what = "word", #Tokenisierung, hier zu W√∂rtern als Analyseeinheit
                 remove_punct = TRUE, #Entfernung von Satzzeichen
                 remove_numbers = TRUE) %>% #Entfernung von Zahlen
  
  # Kleinschreibung
  tokens_tolower() %>% 
  
  # Entfernung von Stoppw√∂rtern
  tokens_remove(stopwords("english")) %>% 
  
  # Stemming
  tokens_wordstem()

# Text-as-Data Repr√§sentation als Document-Feature-Matrix
dfm <- tokens %>% 
  dfm() %>% 
  
  # Relative pruning
  dfm_trim( min_docfreq = 0.005, 
            max_docfreq = 0.99, 
            docfreq_type = "prop", 
            verbose = TRUE) 
```
Jetzt sind wir bereit f√ºr das Topic Modeling!

# 2. Anzahl Themen K
Relevante Entscheidungen f√ºr ein Topic-Modeling umfassen u.a. die Anzahl von Themen `K`, die das Modell identifiziert soll (mit anderen Aspekten, wie der Wahl des Algorithms oder weiterer Hyperparameter, besch√§ftigen wir uns heute nicht).

Zun√§chst m√ºssen wir unsere `dfm` in ein `stm`-Objekt umwandeln, damit das `stm`-Paket, das wir f√ºr die Berechnung des Topic Models brauchen, das Datenformat versteht.
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# DFM in STM-Objekt umwandeln
dfm_stm <- convert(dfm, to = "stm")
```
## 2.1 Statistischer Fit
Ein Kriterium f√ºr die Entscheidung bzgl. K kann die der statistische Fit sein. 

Mit der Funktion `searchK()`aus dem `stm`-Paket berechnen wir den statistischen Fit hier beispielhaft f√ºr Modelle mit 4 vs. 6 Themen. 

Das Argument `verbose`, das wir hier auf `TRUE` setzen, f√ºhrt dazu, dass uns R alle iterativen Berechnungen ausgibt. Wir k√∂nnen also nachverfolgen, was der Computer gerade berechnet.
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE, results = 'hide'}
# dfm_stm$documents: Welche Dokumente nutzen wir?
# dfm_stm$vocab: Welche Features nutzen wir?
stat_fit <- searchK(dfm_stm$documents, dfm_stm$vocab, K = c(4,6), verbose = TRUE)
```
Um das Ergebnis zu interpretieren ploten wir die Daten. Hierf√ºr nutzen wir das Packet `ggplot2` aus dem `tidyverse`-Universum. 
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE} 
# Wir speichern die Ergebnise im Objekt "Plot" ab 
plot <- data.frame("K" = c(4, 6),
                   
                   #Koh√§renz: Je h√∂her, desto besser
                   "Coherence" = unlist(stat_fit$results$semcoh),
                   
                   #Perplexit√§t: Je niedriger, desto besser
                   "Perplexity" = unlist(stat_fit$results$heldout))

# Wir wandeln das Format zu einem "long format" um
plot <- melt(plot, id = c("K"))

#Plot erstellen
ggplot(plot, aes(K, value, color = variable)) +
  geom_line(linewidth = 1.5, show.legend = FALSE) +
  scale_x_continuous(breaks = c(4, 6)) +
  facet_wrap(~ variable, scales = "free_y") +
  labs(x = "Anzahl Themen K",
       title = "Statistischer Fit f√ºr Modelle mit K = 4 und K = 6")
```
Als n√§chstes schauen wir auf die Interpretierbarkeit der Themen!

## 2.2 Inhaltliche Interpretierbarkeit

Eine weitere Grundlage, um sich f√ºr die Anzahl der Themen zu entscheiden, sind *Top Features* und *Top Documents*: Welches Modell ist im Vergleich besser interpretierbar? 

Daf√ºr m√ºssen zun√§chst die einzelnen Modelle mit K = 4 bzw. K = 6 berechnet werden.
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE, results='hide'}
#Model mit K = 4 berechnen
model_4K <- stm(documents = dfm_stm$documents,
                vocab = dfm_stm$vocab, 
                K = 4)

#Model mit K = 6 berechnen
model_6K <- stm(documents = dfm_stm$documents,
                vocab = dfm_stm$vocab, 
                K = 6)
```

### 2.2.1 Top Features ###
Schauen wir uns an, wie interpretierbar die Modelle auf Basis ihrer Features wirken:

Um die Top Features f√ºr jedes Modell zu berechnen, nutzen wir die `labelTopics()`-Funktion aus dem `stm`-Paket. 

Als Argumente bestimmen wir ein Modell sowie √ºber das `n`-Argument, das nur die zehn wichtigsten Features ausgegeben werden sollen. F√ºr den anschliessenden Vergleich speichern wir die Top Features im Objekt `topics_4` bzw. `topics_6` ab:
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Top Features f√ºr K = 4
topics_4K <- labelTopics(model_4K, n = 10)

#Nur Top-10 Features nach Frex-Gewichtung, welche besser interpretierbar ist
#Gewichtet Features nach Koh√§renz und Exklusivit√§t
topics_4K <- data.frame("features" = t(topics_4K$frex))

#Benennung & Ausgabe
colnames(topics_4K) <- paste("Topics", c(1:4))
topics_4K
```

```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
#Top Features f√ºr K = 6
topics_6K <- labelTopics(model_6K, n = 10)

#Nur Top-10 Features nach Frex-Gewichtung, welche besser interpretierbar ist
#Gewichtet Features nach Koh√§renz und Exklusivit√§t
topics_6 <- data.frame("features" = t(topics_6K$frex))

#Benennung & Ausgabe
colnames(topics_6) <- paste("Topics", c(1:6))
topics_6
```

Die Top Features geben bereits einen ersten Eindruck, worum es sich inhaltlich bei den Topics handelt.

### 2.2.1 Top Documents ###
Zus√§tzlich helfen die Top Documents eines Themas, dieses zu interpretieren. Um diese zu finden, nutzen wir die `findThoughts()`-Funktion des `stm`-Pakets. 

Als Argumente werden wieder das jeweilige Modell, die Serienbeschreibungen aus unserem Dataframe via `daten_df$Description`, das zu untersuchende Topic, hier Topic 1, und die Anzahl der zu identifizierenden Top Documents, hier drei, ausgegeben. 

Schauen wir Topic 1 an:
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
findThoughts(model_4K, data$Description, topics = 1, n = 3)
```
Die Top Documents zeigen, √§hnlich wie die Top Features, dass Topic 1 Krimi-Serien zusammenfasst. F√ºr eine Evaluierung der Themen m√ºssen dann f√ºr beide Modelle und alle jeweiligen Themen die Top Documents ausgegeben und die Ergebnisse verglichen werden.

## 2.3. Rank-1 Metrik ##
Mit Hilfe der Rank-1 Metrik l√§sst sich zuletzt zeigen, wie oft ein Thema als Hauptthema vorkommt. Hier wird jedem Dokument ein einziges Hauptthema zugeordnet - n√§mlich das, f√ºr welches das Dokument laut der Document-Topic-Matrix die h√∂chste bedingte Wahrscheinlichkeit hat.

So liessen sich zudem Themen identifizieren, die z. B. wenig pr√§valent und damit ggf. irrelevant sind. Auch l√§sst sich nachverfolgen, wie sich Themen √ºber Modelle mit z. B. mehr K in mehrere Themen "aufsplitten".

Im ersten Schritt berechnen wir die Document-Topic-Matrix, in der f√ºr jeden Dokument zusammengefasst wird, welches Thema wie gut zum Dokument passt. Das machen wir mit der `make.dt()`Funktion aus dem `stm`-Paket.
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
theta_4K <- make.dt(model_4K)
theta_6K <- make.dt(model_6K)

#Schauen wir uns kurz beispielhaft die Matrix an:
theta_4K %>%
  head()
```

Jetzt nehmen wir diese Matrix und ordnen jedem Dokument das Thema mit der h√∂chsten Pr√§valenz zu. 

Das machen wir einmal f√ºr K = 4.
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Zuerst erstellen wir zwei leere Spalten in unserem Dataframe data
data <- data %>%
  
  #Anzahl der Themen, wird sp√§ter "aufgef√ºllt"
  mutate(Rank1_K4 = NA,
         Rank1_K6 = NA)

# Berechnung von Rank-1 Metrik
for (i in 1:nrow(data)){ # Schleife: F√ºr jede nachfolgende Zeile...
  
  # Bestimme Hauptthema f√ºr K = 4
  column <- theta_4K[i,-1] # W√§hle alle Spalten der Document-Topic-Matrix aus (ohne die erste, die nur doc_id enth√§lt)
  maintopic <- colnames(column)[which(column == max(column))] # Bestimmung des Hauptthemas (Spalte mit dem h√∂chsten Wert)
  data$Rank1_K4[i] <- maintopic # Zuweisung des Hauptthemas zur entsprechenden Zeile im Datenrahmen
  rm(column, maintopic)
  
  # Bestimme Hauptthema f√ºr K = 6
  column <- theta_6K[i,-1] # W√§hle alle Spalten der Document-Topic-Matrix aus (ohne die erste, die nur doc_id enth√§lt)
  maintopic <- colnames(column)[which(column == max(column))] # Bestimmung des Hauptthemas (Spalte mit dem h√∂chsten Wert)
  data$Rank1_K6[i] <- maintopic # Zuweisung des Hauptthemas zur entsprechenden Zeile im Datenrahmen
  rm(column, maintopic)
}
```

Schauen wir uns an, wie h√§ufig jedes Thema bei K = 4 vorkommt!
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Erzeugung einer H√§ufigkeitstabelle f√ºr Rank-1 Themen bei K = 4
data %>%
  
  # absolute Anzahl jedes Themas
  count(Rank1_K4) %>%
  
  # Ausgabe in Prozent (perc)
  mutate(perc = prop.table(n)*100,
         perc = round(perc, 2))
```
Und jetzt das gleiche f√ºr K = 6
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Erzeugung einer H√§ufigkeitstabelle f√ºr Rank-1 Themen bei K = 6
data %>%
  
  # absolute Anzahl jedes Themas
  count(Rank1_K6) %>%
  
  # Ausgabe in Prozent (perc)
  mutate(perc = prop.table(n)*100,
         perc = round(perc, 2))
```

Die Ergebnisse zeigen, dass bei K = 6 die Verteilung der Dokumente wesentlich gleichm√§√üiger ausf√§llt. 

F√ºr eine endg√ºltige Entscheidung von K sollten diese Metriken f√ºr deutlich mehr als zwei Ks ausgegeben werden. 

In diesem Fall deuten die ersten Ergebnisse darauf hin, dass ein Modell mit 6 Themen den TV-Seriendatensatz ggf. besser abbildet als ein Modell mit 4 Themen. 

# 3. Analyse

## 3.1 Einfluss unabh√§ngiger Variablen
F√ºr eine beispielhafte Analyse nehmen wir nun an, dass wir uns f√ºr K = 6 Themen entschieden haben. Mit dem `stm`-Paket k√∂nnen wir als weiteren Analyseschritt eine unabh√§ngige Variable einzubeziehen, um die Pr√§valenz (`prevalence`-Argument) oder den Inhalt (`content`-Argument) von Themen zu modellieren:

Gehen wir **als Arbeitshypothese** davon aus, dass das Jahr, in dem eine Serie zuerst ausgestrahlt wurde, einen Einfluss auf das dort beschriebene Thema hat.

Beispielsweise k√∂nnte es sein, dass unterschiedliche Jahre von unterschiedlichen "Genres" gepr√§gt wurden.

Zun√§chst nutzen wir wieder regul√§re Ausdr√ºcke, um das Erstausstrahlungs-Jahr aller Serien zu identifizieren. Bitte beachtet dabei, dass wir fehlende Werte einfach mit dem Mittelwert von `Start_Year` ersetzen. Das w√ºrde man normalerweise nicht machen, aber fehlende Werte f√ºr unabh√§ngige Variablen sind im `stm`-Paket h√∂llisch schwierig zu handeln - das tun wir uns heute nicht an.
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
data <- data %>%
  
  # Wir entfernen alle nicht-numerische Zeichen, um "-" zu entfernen
  mutate(Year_Start = gsub("[^0-9]", "", Year),
         
         # Wir beschr√§nken uns nur auf die ersten 4 Jahre
         Year_Start = substr(Year_Start, 1, 4),
         
         # Wir verwandeln das ganze in eine numerische Variable
         Year_Start = as.numeric(Year_Start),
         
         #Wir ersetzen fehlende Werte mit dem Mittelwert (2010)
         Year_Start = replace(Year_Start,
                              is.na(Year_Start),
                              2010))

#Ausgabe der ersten Zeilen
head(data)
```
Dann nehmen wir die Variable `Year_Start` als unabh√§ngige Variable in unser Modell auf, um die Pr√§valenz von Themen zu modellieren:
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE, results='hide'}
# Wir lassen das angepasste Modell laufen
model_6K_year <- stm(documents = dfm_stm$documents,
                     vocab = dfm_stm$vocab, 
                     K = 6,
                     prevalence = ~ Year_Start, #neu!
                     data = data)
```
Jetzt k√∂nnen wir mit der Funktion `estimateEffect()` aus dem `stm`-Paket berechnen, inwiefern das Erscheinungsjahr einer Serie einen Einfluss auf das dort behandelte Thema hat:
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
effect <- estimateEffect(formula = ~ Year_Start, 
                         stmobj = model_6K_year, 
                         metadata = data)
```

Diesen Effekt k√∂nnen wir nun auch grafisch darstellen. Bsp. wollen wir wissen: Hat das Erscheinungsjahr einen Effekt darauf, wie h√§ufig Serien z.B. Drama (Topic 2) vs. Sci-Fi (Topic 4) darstellen?
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
topics_6 %>%
  select(`Topics 2`, `Topics 4`)
```
Wir plotten die Ergebnisse und sehen - es scheint Unterschiede √ºber die Zeit hinweg zu geben!
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
plot(effect, "Year_Start", 
     method = "continuous", 
     topics = c(2,4), 
     model = model_6K_year)
```
## 3.2 Visualisierung des Topic Models
Um unser Modell zu verstehen, k√∂nnen wir es zudem mit dem `stminsights`-Paket visualisieren. Daf√ºr...

- erstellen wir zun√§chst das Objekt `out`, indem alle wichtigen Infos gespeichert sind
- starten wir dann die zugeh√∂rige Shiny-App mit `run_stminsights()`
- laden dort anschliessend unser R-Environment hoch. 

Dieses findet ihr unter Sitzung 4 zum Download ([hier](https://valeriehase.github.io/textasdata-ms/data/Sitzung4.RDATA)), solltest ihr bis hierhin Probleme gehabt haben, den Code auszuf√ºhren.
```{r echo = TRUE, eval = FALSE, message = FALSE, warning = FALSE, error = FALSE}
# Wir erstellen das Objekt out, in dem alle wichtigen Infos gespeichert sind
# Das stminsights-Paket ben√∂tigt dieses Format
out <- list(documents = dfm_stm$documents,
            vocab = dfm_stm$vocab,
            meta = dfm_stm$meta)

# Wir speichern das Environment ab, um es hochzuladen
save.image("Sitzung4.RDATA")

# Wir lassen die Shiny App laufen
run_stminsights()
```
# Aufgabe 1 üìå

## Aufgabe 1.1 (Basis)
K√∂nnt ihr testen, wie sich das Modell ver√§ndert, wenn wir mit K = 10 Serien arbeiten? Wird es besser oder schlechter interpretierbar?

## Aufgabe 1.2 (Fortgeschritten)
K√∂nnt ihr mittels des Datensatzes zu Horoskopen testen, ob Zwillinge und Wasserm√§nner andere Themen in ihren Horoskopen vorhergesagt kriegen?