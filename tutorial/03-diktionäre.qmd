---
title: "Sitzung 3: Diktion√§re"
author: "Valerie Hase & Luisa Kutlar"
format:
  html:
    toc: true
    html-math-method: katex
    css: styles.css
---

# 1. Pakete laden und Daten einlesen

Zun√§chst installieren alle Pakete, die wir f√ºr diese Sitzung brauchten (z.B. `tidyverse`). Ihr braucht `install.packages()` nur, wenn ihr die Pakete im Methodencafe noch nicht installiert hattet.

```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
#install.packages("tidyverse)
#install.packages("RCurl")
#install.packages("quanteda")

library("tidyverse")
library("RCurl")
library("quanteda")
```
Nun lesen wir die Daten wieder ein und f√ºhren die bereits erlernten Preprocessing-Schritte, inkl. der Transformation in eine Document-Feature-Matrix, aus.

Wir lassen einige Preprocessing-Schritte (u.a. die Entfernung von Stoppw√∂rtern, Stemming, Relative Pruning) diesmal weg, u. a. weil das von uns genutzte Diktion√§r bereits gestemmte Features enth√§lt und weil wir z. B. seltene negative/positive W√∂rter hier nicht entfernen wollen:
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Daten laden
url <-  getURL("https://raw.githubusercontent.com/valeriehase/textasdata-ms/main/data/data_tvseries.csv")
data <- read.csv2(text = url)

# Preprocessing
tokens <- tokens(data$Description,
                 what = "word", #Tokenisierung, hier zu W√∂rtern als Analyseeinheit
                 remove_punct = TRUE, #Entfernung von Satzzeichen
                 remove_numbers = TRUE) %>% #Entfernung von Zahlen
  
  # Kleinschreibung
  tokens_tolower()

# Text-as-Data Repr√§sentation als Document-Feature-Matrix
dfm <- tokens %>% 
  dfm() 
```
Jetzt sind wir bereit f√ºr die ersten Analysen mit Diktion√§ren!

# 2. Off-the-Shelf Diktion√§re

## 2.1 Diktion√§r ausw√§hlen
Es gibt viele off-the-Shelf Diktion√§re. Der Einfachkeit halber nutzen wir hier zur Demonsrtation das `data_dictionary_LSD2015`-Diktion√§r aus dem `quanteda`- Paket (Young & Soroka, 2012).
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Wir schauen uns das Diktion√§r an
data_dictionary_LSD2015 %>% 
  head()
```
## 2.2 Features aus Diktion√§r identifizieren
Mit der Funktion `dfm_lookup()` aus dem quanteda Packet wird f√ºr jeden Text, also in diesem Fall f√ºr jede TV-Show, geschaut, wie viele W√∂rter aus den ersten zwei Spalten des Diktion√§rs (positive bzw. negative W√∂rter) vorkommen. 

Die Funktion `dfm_weight(scheme = "prop")` setzt die Anzahl der Features, die gematched werden, ins Verh√§ltnis mit der L√§nge des Textes, d.h. normalisiert f√ºr diese. 

Dadurch erhalten l√§ngere Texte nicht f√§lschlicherweise einen "h√∂heren" Match mit Features aus dem Diktion√§r, nur weil sie generell mehr W√∂rter enthalten (und damit ggf. "zuf√§llig" ein positives oder negatives Wort enthalten).
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
sentiment_tvshows <- dfm %>% 
  
  # Suche nach Features aus Diktion√§r
  # Gewichtung relativ zur Anzahl aller W√∂rter
  dfm_weight(scheme = "prop") %>% 
  dfm_lookup(dictionary = data_dictionary_LSD2015[1:2])

# Ausgabe der Ergebnisse
sentiment_tvshows %>% 
  head()
```
Wir sehen z. B. f√ºr die allerste Beobachtung, die Beschreibung von *Game of Thrones*:

```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
data$Description[1]
```

- Der erste Text enth√§lt **ein** Feature, das mit positivem Sentiment assoziiert wird ("*noble*"). Bei insgesamt 21 Features im Satz sind das 4.76% positives Sentiment f√ºr diese Serienbeschreibung.
- Der erste Text enth√§lt **zwei** Features, die mit negativem Sentiment assoziiert werden ("*fight*", "*enemy*"). Bei insgesamt 21 Features im Satz sind das 9.52% positives Sentiment f√ºr diese Serienbeschreibung.

## 2.3 Texte klassifizieren
Welche Analysen k√∂nnten wir jetzt vornehmen?

Wir k√∂nnten z. B. Texte als neutral, positiv oder negativ einstufen (je nachdem, ob sie gleich viele oder mehr/weniger positive bzw. negative Feature enthalten).

Dazu m√ºssen wir das Ergebnis mit `convert()` zu einem Dataframe unwandeln.
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Ergebnis f√ºr die weitere Analyse in einen Dataframe umwandeln
sentiment_tvshows <- convert(sentiment_tvshows, 
                             to = "data.frame") %>%
  
  # Umwandlung in tibble-Format
  as_tibble %>%
  
  # Wir erg√§nzen zun√§chst wieder die Serientitel & das "Parental-Rating"
  mutate(Title = data$Title,
         Parental.Rating = data$Parental.Rating) %>%
  
  # Wir erstellen eine Variable, die Texte als
  # "neutral", "positiv" oder "negativ" identifiziert
  
  # Zun√§chst gelten alle Texte als "neutral"
  mutate(sentiment = "neutral",
         
         # Falls mehr pos. als neg: "positiv"
         sentiment = replace(sentiment,
                             positive > negative,
                             "positiv"),

         # Falls mehr neg. als pos.: "negativ"
         sentiment = replace(sentiment,
                             positive < negative,
                             "negativ")) %>%

# Sortierung der Variablen
select(Title, Parental.Rating, positive, negative, sentiment)

# Ausgabe des Ergebnis
sentiment_tvshows %>%
  head()
```
Dann k√∂nnten wir mit `count()` aus dem `tidverse`-Paket analysieren, wie viele Texte positiv vs. negativ sind:
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Anzahl neutral, negativer und positiver Texte?
sentiment_tvshows %>%
  
  # absolute Anzahl jeder Sentiment-Art (n)
  count(sentiment) %>%
  
  # Ausgabe in Prozent (perc)
  mutate(perc = prop.table(n)*100,
         perc = round(perc, 2))

```
Insgesamt scheinen die beliebtesten Serien also recht d√ºster zu sein. Welche sind denn die negativsten Serien laut unserer Sentiment-Analyse?

Hierf√ºr nutzen die wir `arrange()`-Funktion aus dem `tidyverse`-Paket.
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Negativste Serien
sentiment_tvshows %>% 
  arrange(desc(negative)) %>% 
  slice(1:5)
```
Und welche die positivsten?
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
# Positivste Serien
sentiment_tvshows %>% 
  arrange(desc(positive)) %>% 
  slice(1:5)
```
## 2.4 Gruppenvergleich
Jetzt k√∂nnen wir noch visualisieren, ob Serien mit "h√∂herem" Parental-Rating auch negativer sind.

Daf√ºr erstellen wir zun√§chst eine Variable `Rating.Adults`, die kennzeichnet, ob Serien als *TV-MA*, d.h. als ungeeignet f√ºr Jugendliche und Kinder bis inkl. 17 Jahren eingestuft wurden, oder nicht bzw. die Serie nicht gerated wurde:

```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
sentiment_tvshows <- sentiment_tvshows %>% 
  
  #Erstellen eines "Rating.Adults"-Klassifizierungs-Variable
  mutate(Rating.Adults = 0,
         Rating.Adults = replace(Rating.Adults,
                                 Parental.Rating == "TV-MA",
                                 1))

#Wir schauen uns die Ergebnisse an
head(sentiment_tvshows)
```
F√ºr die Visualisierung nutzen wir hier die `ggplot()`-Funktion aus dem `tidyverse`-Paket. Wenn ihr noch nie mit ggplot gearbeitet habt, braucht ihr den nachfolgenden Code nicht im Detail verstehen (s. ein l√§ngere Tutorial [hier](https://bookdown.org/valerie_hase/DataDonations-TextasData/tutorial-8-visualizing-results.html)).

Zun√§chst erstellen wir das Objekt `plot`, das durch `group_by()` aus dem `tidyverse`-Paket die nach Rating gruppierten Werte enth√§lt.
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
plot <- sentiment_tvshows %>%
  
  # Wir berechnen die gruppierten H√§ufigkeiten
  group_by(Rating.Adults) %>%
  
  # absolute Anzahl jeder Sentiment-Art (n)
  count(sentiment) %>%
  
  # Ausgabe in Prozent (perc)
  mutate(perc = prop.table(n)*100,
         perc = round(perc, 2)) %>%
  
  # Wir heben die Gruppierung auf
  ungroup()

# Visualisierung
ggplot(plot, aes(fill = Rating.Adults, y = perc, x = sentiment)) + 
  
  # Wir kreiern den entsprechenden Graphen
  geom_bar(stat ="identity") +
  
  # Wir f√ºgen Achsenbeschriftungen hinzu
  labs(y = "% negatives, neutrales und positives Sentiment", 
       x = "Sentiment",
       title = "Sentiment in TV-Serien",
       colour = "Sentiment") +
 
  # Wir √§ndern das Background-Design
  theme_light() + 
  
  # Wir entfernen die Legende, die wenig hilfreich ist
  theme(legend.position = "none")
```
# 3. Organische Diktion√§re 
Oftmals kann es sinnvoller sein, ein eigenes, sogenanntes "organisches" Diktion√§r zu entwickeln. 

## 3.1 Diktion√§r erstellen
Daf√ºr erstellen wir zun√§chst mit `dictionary()` aus dem `quanteda`-Paket eine eigene Wortliste. Hier wollen wir auf Basis eines organischen Diktion√§rs Serien identifizieren, die sich mit "*Crime*" besch√§ftigen (√§hnlich wie in Sitzung 1!).
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
diktion√§r_crime <- dictionary(list(crime = c("crim*", "police*", "gun*", 
                                             "shot*", "dead*", "murder*", 
                                             "kill*", "court*", "suspect*", 
                                             "witness*", "arrest*", "officer*", 
                                             "verdict*")))
```

## 3.2 Features aus Diktion√§r identifizieren
Dann werten wir die Ergebnisse gleichermassen aus:
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
#Diktion√§r anwenden
crime_tvshows <- dfm %>% 
  dfm_weight(scheme = "prop") %>% 
  dfm_lookup(dictionary = diktion√§r_crime)

# Ergebnis f√ºr die weitere Analyse in einen Data Frame umwandeln
crime_tvshows <- convert(crime_tvshows, 
                         to = "data.frame") %>%
  
  # Umwandlung in tibble-Format
  as_tibble %>%
  
  # Wir erg√§nzen zun√§chst wieder die Serientitel
  mutate(Title = data$Title) %>%
  
  # Wir erstellen eine Variable, die Texte als
  # "crime" oder "non-Crime" identifiziert
  mutate(crime_binary = "crime",
         crime_binary = replace(crime_binary,
                         crime == 0,
                         "non-crime")) %>%

# Sortierung der Variablen
select(Title, crime, crime_binary)

#Ausgabe der Ergebnisse
head(crime_tvshows)
```
## 3.3 Texte klassifizieren
Dann k√∂nnten wir analysieren, wie viele Serien Krimi-Serien sind (oder eben nicht):
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
#Ausgabe der Crime vs. Non-Crime Serien
crime_tvshows %>%
  
  # absolute Anzahl jeder Sentiment-Art (n)
  count(crime_binary) %>%
  
  # Ausgabe in Prozent (perc)
  mutate(perc = prop.table(n)*100,
         perc = round(perc, 2))
```
Und welche Serie wird am "klarsten" als Krimi eingestuft?
```{r echo = TRUE, message = FALSE, warning = FALSE, error = FALSE}
crime_tvshows %>% 
  arrange(desc(crime)) %>% 
  slice(1:5)
```
# Aufgabe 1 üìå

Die folgende √úbung testet eure Kenntnisse im Hinblick auf Diktion√§re!

## Aufgabe 1.1 (Basis)
K√∂nnt ihr analysieren, wie viel Prozent der Serien Science-Fiction Serien sind?
```{r echo = FALSE, eval = FALSE, message = FALSE, warning = FALSE, error = FALSE}
#Diktion√§r erstellen
diktion√§r_scifi <- dictionary(list(scifi = c("fantas*", "science fict*", "sci-fi*", 
                                             "sci fi*", "galax*", "space*",
                                             "magic*", "wizzard*", "witch*",
                                             "monster")))

#Diktion√§r anwenden
scifi_tvshows <- dfm %>% 
  dfm_weight(scheme = "prop") %>% 
  dfm_lookup(dictionary = diktion√§r_scifi)

# Ergebnis f√ºr die weitere Analyse in einen Data Frame umwandeln
scifi_tvshows <- convert(scifi_tvshows, 
                         to = "data.frame") %>%
  
  # Umwandlung in tibble-Format
  as_tibble %>%
  
  # Wir erg√§nzen zun√§chst wieder die Serientitel
  mutate(Title = data$Title,
         Number.of.Votes = data$Number.of.Votes) %>%
  
  # Wir erstellen eine Variable, die Texte als
  # "scifi" oder "non-scifi" identifiziert
  mutate(scifi_binary = "scifi",
         scifi_binary = replace(scifi_binary,
                         scifi == 0,
                         "non-scifi")) %>%

# Sortierung der Variablen
select(Title, Number.of.Votes, scifi, scifi_binary)

# Wie viel Prozent sind Sci-Fi Serien?
scifi_tvshows %>%
  
  # absolute Anzahl jeder Sentiment-Art (n)
  count(scifi_binary) %>%
  
  # Ausgabe in Prozent (perc)
  mutate(perc = prop.table(n)*100,
         perc = round(perc, 2))

```
## Aufgabe 1.2 (Fortgeschritten)
K√∂nnt ihr analysieren, welche f√ºnf Science-Fiction Serien die (nach Publikums-Votum laut `Number.of.Votes`) beliebtesten Serien sind?
```{r echo = FALSE, eval = FALSE, message = FALSE, warning = FALSE, error = FALSE}
#Diktion√§r erstellen
scifi_tvshows %>%
  
  #Auswahl der Sci-Fi-Serien
  filter(scifi_binary == "scifi") %>%
  
  #Umwandlung der Number.of.Votes Variable
  mutate(Number.of.Votes = gsub("K", "000000", Number.of.Votes),
         Number.of.Votes = gsub("M", "000000000", Number.of.Votes),
         Number.of.Votes = as.numeric(Number.of.Votes)) %>%
  
  #Sortierung nach Rating
  arrange(desc(Number.of.Votes)) %>%
  
  #Ausgabe der ersten f√ºnf Serien
  head(5)
```